<!DOCTYPE html>
<html lang="en">
<head>
    <title>A-Frame Image Tracking Example</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    
    <!-- Import A-Frame and AR.js -->
    <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar-nft.js"></script>

    <!-- OpenCV -->
    <script async src="https://docs.opencv.org/master/opencv.js"></script>

    <!-- Custom scripts -->
    <script src="js/gesture-detector.js"></script>
    <script src="js/gesture-handler.js"></script>

    <!-- Styles for the loader -->
    <style>
        .arjs-loader {
            height: 100%;
            width: 100%;
            position: absolute;
            top: 0;
            left: 0;
            background-color: rgba(0, 0, 0, 0.8);
            z-index: 9999;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .arjs-loader div {
            text-align: center;
            font-size: 1.25em;
            color: white;
        }
    </style>
        
</head>
<body style="margin: 0; overflow: hidden;">
    <!-- Loading overlay -->
    <div class="arjs-loader">
        <div>Loading, please wait...</div>
    </div>

    <!-- A-Frame scene -->
    <a-scene
        vr-mode-ui="enabled: false;"
        renderer="logarithmicDepthBuffer: true;"
        embedded
        gesture-detector
        arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;"
        tensorflow-contour-processor
    >
        <a-assets>
            <a-asset-item id="sandcastleModel" src="assets/sand-castle.glb"></a-asset-item>
        </a-assets>
        
        <a-nft
            type="nft"
            url="https://raw.githack.com/Shinijuana/ARDOSMARkER/main/images/nft/dos"
            smooth="true"
            smoothCount="10"
            smoothTolerance=".01"
            smoothThreshold="5"
            raycaster="objects: .clickable"
            emitevents="true"
            cursor="fuse: false; rayOrigin: mouse;"
            id="nftMarker"
        >
            <a-entity
                id="sandcastle"
                gltf-model="https://raw.githack.com/Shinijuana/ARDOSMARkER/main/assets/busto%20emilio.gltf"
                scale="100 100 100"
                position="40 0 -60"
                gesture-handler
                class="clickable" 
            >
            </a-entity>
        </a-nft>
       
        <a-entity camera></a-entity>
       
    </a-scene>

    <!-- OpenCV TensorFlow Script -->
    <script>
        window.onOpenCvReady = () => {
            cv.onRuntimeInitialized = () => {
                console.log('OpenCV.js is ready.');

                AFRAME.components['tensorflow-contour-processor'].initializeWebcamAndCanvas();
            };
        };

        AFRAME.registerComponent('tensorflow-contour-processor', {
            schema: {
                targetName: { type: 'string' },
            },

            init() {
                this.loadOpenCV();
            },

            loadOpenCV() {
                console.log('Loading OpenCV.js...');
                if (!window.cv) {
                    const opencvScript = document.createElement('script');
                    opencvScript.src = 'https://docs.opencv.org/master/opencv.js';
                    opencvScript.async = true;
                    opencvScript.onload = () => {
                        console.log('OpenCV.js script loaded.');
                    };
                    opencvScript.onerror = () => {
                        console.error('Failed to load OpenCV.js script.');
                    };
                    document.head.appendChild(opencvScript);
                } else {
                    console.log('OpenCV.js is already loaded.');
                    onOpenCvReady();
                }
            },

            initializeWebcamAndCanvas() {
                const video = document.querySelector('video');
                const canvas = document.createElement('canvas');
                document.body.appendChild(canvas);
                const ctx = canvas.getContext('2d');

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                const processFrame = () => {
                    ctx.drawImage(video, 0, 0);
                    const src = cv.imread(canvas);
                    const dst = new cv.Mat();
                    cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
                    cv.Canny(src, dst, 50, 100);
                    cv.imshow(canvas, dst);

                    src.delete();
                    dst.delete();
                    requestAnimationFrame(processFrame);
                };
                requestAnimationFrame(processFrame);
            },

            remove() {
                const canvas = document.querySelector('canvas');
                if (canvas) {
                    document.body.removeChild(canvas);
                }
                console.log('Cleanup complete.');
            },
        });
    </script>
</body>
</html>
