<!DOCTYPE html>
<html lang="en">
<head>
    <title>A-Frame AR.js with OpenCV</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- A-Frame and AR.js -->
    <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar-nft.js"></script>

    <!-- OpenCV -->
    <script async src="https://docs.opencv.org/master/opencv.js"></script>

    <!-- Custom scripts -->
    <script src="js/gesture-detector.js"></script>
    <script src="js/gesture-handler.js"></script>

    <!-- Styles for loader -->
    <style>
        .arjs-loader {
            height: 100%;
            width: 100%;
            position: absolute;
            top: 0;
            left: 0;
            background-color: rgba(0, 0, 0, 0.8);
            z-index: 9999;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .arjs-loader div {
            text-align: center;
            font-size: 1.25em;
            color: white;
        }
    </style>
        
</head>
<body style="margin: 0; overflow: hidden;">
    <!-- Loading overlay -->
    <div class="arjs-loader">
        <div>Loading, please wait...</div>
    </div>

    <!-- A-Frame Scene -->
    <a-scene
        vr-mode-ui="enabled: false;"
        renderer="logarithmicDepthBuffer: true;"
        embedded
        gesture-detector
        arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;"
        opencv-tracker
    >
        <a-assets>
            <a-asset-item id="sandcastleModel" src="assets/sand-castle.glb"></a-asset-item>
        </a-assets>
        
        <a-nft
            type="nft"
            url="https://raw.githack.com/Shinijuana/ARDOSMARkER/main/images/nft/dos"
            smooth="true"
            smoothCount="10"
            smoothTolerance=".01"
            smoothThreshold="5"
            raycaster="objects: .clickable"
            emitevents="true"
            cursor="fuse: false; rayOrigin: mouse;"
            id="nftMarker"
        >
            <a-entity
                id="sandcastle"
                gltf-model="https://raw.githack.com/Shinijuana/ARDOSMARkER/main/assets/busto%20emilio.gltf"
                scale="100 100 100"
                position="30 0 -60"
                class="clickable" 
            >
            </a-entity>
        </a-nft>
       
        <a-entity camera></a-entity>
    </a-scene>

    <!-- OpenCV Tracker Script -->
    <script>
        AFRAME.registerComponent('opencv-tracker', {
            init: function () {
                console.log("Initializing OpenCV Tracker...");

                // Get video feed from AR.js
                const video = document.querySelector('video');
                if (!video) {
                    console.error("No video element found for AR.js");
                    return;
                }

                // Create a canvas for processing
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');
                document.body.appendChild(canvas);

                video.addEventListener('play', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;

                    const processFrame = () => {
                        if (video.paused || video.ended) {
                            return;
                        }

                        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                        const src = cv.imread(canvas);
                        const dst = new cv.Mat();
                        
                        // Convert to grayscale
                        cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
                        
                        // Apply Canny edge detection
                        cv.Canny(dst, dst, 50, 100);
                        
                        // Find contours
                        const contours = new cv.MatVector();
                        const hierarchy = new cv.Mat();
                        cv.findContours(dst, contours, hierarchy, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE);

                        // Update model position based on contours
                        this.updateModelPosition(contours);

                        src.delete();
                        dst.delete();
                        contours.delete();
                        hierarchy.delete();

                        requestAnimationFrame(processFrame);
                    };

                    requestAnimationFrame(processFrame);
                });
            },

            updateModelPosition: function (contours) {
                const model = document.querySelector('#sandcastle');
                if (contours.size() > 0) {
                    // Logic to stabilize model position based on contours
                    const rect = cv.boundingRect(contours.get(0));
                    
                    const centerX = rect.x + rect.width / 2;
                    const centerY = rect.y + rect.height / 2;
                    
                    // Normalize position based on video dimensions
                    const normX = (centerX / canvas.width) * 2 - 1;
                    const normY = (centerY / canvas.height) * 2 - 1;

                    // Update model position (adjust scaling and offsets as necessary)
                    model.object3D.position.set(normX, -normY, 0);
                    
                    model.setAttribute('visible', true);
                } else {
                    // If no contours found, hide or freeze the model in the last known position
                    model.setAttribute('visible', false);
                }
            }
        });
    </script>

</body>
</html>
